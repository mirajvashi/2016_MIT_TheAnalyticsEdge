source("LoadLib.r")
emails <- read.csv("emails.csv", stringsAsFactors = FALSE)
str(emails)
table(emails$spam)
summary(emails)
emails$text[1]
emails$text[2]
substr(emails$text[1],1,10)
substr(emails$text[1],0,10)
substr(emails$text[1],2,10)
substr(emails$text[1],1,10)
substr(emails$text[1:10],1,10)
max(nchar(emails$text))
which.min(nchar(emails$text))
########################### BUILD DOCUMENT TERM MATRIX #######################
library(tm)
library(tm)
corpus = Corpus(VectorSource(emails$text))
corpus = tm_map(corpus, tolower)
corpus = tm_map(corpus, PlainTextDocument)
corpus = tm_map(corpus, removePunctuation)
corpus = tm_map(corpus, removeWords, stopwords("english"))
corpus - tm_map(corpus, stemDocument)
corpus <- tm_map(corpus, stemDocument)
dtm <- DocumentTermMatrix(corpus)
dtm
spdtm <- removeSparseTerms(ddtm, 0.95)
spdtm <- removeSparseTerms(dtm, 0.95)
spdtm
emailsSparse = as.data.frame(as.matrix(spdtm))
which.max(colSums(emailsSparse))
emailsSparse$spam <- emails$spam
colSums(subset(emailsSparse, spam == 0))
colSums(subset(emailsSparse, spam == 0)) > 5000
a<- colSums(subset(emailsSparse, spam == 0))
a
sort(a, decreasing = TRUE)
names(1)
names(a)
names(a)[a>5000]
a <- colSums(subset(emailsSparse, spam == 1))
names(a)[a>1000]
names(a)[a>=1000]
sort(colSums(subset(emailsSparse, spam == 1)), decreasing = TRUE)
colnames(emailsSparse) = make.names(colnames(emailsSparse))
##################### BUILDING MACHINE LEARNING MODELS ##########################
str(emailsSparse)
str(emailsSparse$spam)
emailsSparse$spam = as.factor(emailsSparse$spam)
str(emailsSparse$spam)
set.seed(123)
splt = sample.split(emailsSparse$spam, SplitRatio = 0.70)
Train = subset(emailsSparse, splt == TRUE)
Test = subset(emailsSparse, splt == FALSE)
spamLog = glm(spam ~ ., data = Train, family = "binomial")
spanCART <- rpart(spam ~ ., data = Train, method = "class")
set.seed(123)
spamCART = spanCART
rm(spanCART)
set.seed(123)
spamRF = randomForest(spam ~ ., data = Train)
predSpamLog = predict(spamLog, type = "response")
predSpamCART = predict(spamCART)
predSpamRF = predict(spamRF, type = "prob")
sink("RF.txt")
print("Summary Of Random Forest Model...\n")
summary(spamRF)
print("\n\nSummary Of CART Model...\n")
summary(spamCART)
print("\n\nSummary Of Logistic Regression Model...\n")
summary(spamLog)
sink()
print("\n\nSummary Of Logistic Regression Model...\n")
prp(spamCART)
sum(predSpamLog < 0.00001)
sum(predSpamLog > 0.99999)
length(predSpamLog) - 3046-954
summary(spamLog)
table(Train$spam, predSpamLog > 0.5)
(3052+954)/nrow(Train)
table(Test$spam, predict(spamLog, newdata = Test, type = "response") > 0.5)
(1257+376)/nrow(Test)
predRSpamLog <- prediction(predSpamLog, Train$spam)
as.numeric(peroformance(predRSpamLog, "auc")@y.values)
as.numeric(performance(predRSpamLog, "auc")@y.values)
table(Train$spam, predict(spamCART, tpye = "class"))
table(Train$spam, predict(spamCART, type = "class"))
(2885+894)/nrow(Train)
as.numeric(performance(prediction(predSpamCART[ ,2], Train$spam), "auc")@y.values)
table(Train$spam, predict(spamRF, type = "class"))
(3013+918)/nrow(Train)
as.numeric(performance(prediction(predSpamRF[ ,2], Train$spam), "auc")@y.values)
predTLog = predict(spamLog, newdata = Test, type = "response")
predTCART = predict(spamCART, newdata = Test)
predTRF = predict(spamRF, newdata = Test, type = "prob")
table(Test$spam, predTLog > 0.5)
(1257+376)/nrow(Test)
as.numeric(performance(prediction(predTLog, Test$spam), "auc")@y.values)
table(Test$spam, predTCART[ ,2] > 0.5)
as.numeric(performance(prediction(predTCART[ ,2], Test$spam), "auc")@y.values)
(1228+386)/nrow(Test)
(1228+386)/length(predTCART)
table(Test$spam, predTRF[ ,2] > 0.5)
(1290+384)/norw(Test)
(1290+384)/nrow(Test)
as.numeric(performance(prediction(predRF[ ,2], Test$spam), "auc")@y.values)
as.numeric(performance(prediction(predTRF[ ,2], Test$spam), "auc")@y.values)
############################# OPTIONAL HOME WORK  #####################################
############################# OPTIONAL HOME WORK  #####################################
############################# OPTIONAL HOME WORK  #####################################
wordCount = rowSums(as.matrix(dtm))
install.packages("slam")
install.packages("slam")
library(slam)
wordCount = rollup(dtm, 2, FUN=sum)$v
hist(wordCount)
hist(log(wordCount))
emailsSparse$logWordCount = log(wordCount)
boxplot(emailsSparse$spam ~ emailsSparse$logWordCount)
str(emailsSparse$logWordCount)
str(emailsSparse$spam)
boxplot(emailsSparse$spam, emailsSparse$logWordCount)
boxplot(emailsSparse$logWordCount, emailsSparse$spam)
boxplot(emailsSparse$logWordCount ~ emailsSparse$spam)
Train2 <- subset(emailsSparse, splt == TRUE)
Test2 <- subset(emailsSparse, splt == FALSE)
source(LoadLib.r)
source("LoadLib.r")
spam2CART <- rpart(spam ~., data = Train2, method = "class")
set.seed(123)
spam2RF <- randomForest(spam ~ ., data = Train2)
prp(spam2CART)
predTCART2 <- predict(spam2CART, newdata = Test2)
predTRF2 <- predict(spam2RF, newdata = Test2, type = "prob")
table(Test$spam, predTCART2[ ,2] >0.5)
(1214+384)/nrow(Test2)
as.numeric(performance(prediction(predTCART2[ ,2], Test2$spam), "auc")@y.values)
table(Test$spam, predTRF2[ ,2] >0.5)
(1298+379)/nrow(Test2)
as.numeric(performance(prediction(predTRF2[ ,2], Test2$spam), "auc")@y.values)
